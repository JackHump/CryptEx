### SPLICE JUNCTION ANALYZER
# This script will load in the DEXSeq results.
# The end goal is to create a data frame with the cryptic exons accompanied by a  count of the number of splice junctions from the upstream exon to the cryptic exon and from the cryptic exon to the downstream exon and a count of splice junctions from the upstream to the downstream exon. These counts will give me a Cryptic Exon statistic I can use to filter out junk that comes out as significant.
# The DEXSeq output gives an exonID for each cryptic exon in the format "001i". The upstream exon would be 001 and the downstream is 002. 
# The upstream and downstream exon coordinates can be taken from the exon GFF.
# The splice junction counts can be taken from the SJ.tab files generated by STAR. They can be treated like a bed file. These files are in the same directory as the starting bam and so can be found using the support file.
# One technical challenge is that due to the merging step in the Step2 process, the cryptic exon coordinates may be slightly larger than the "true" cryptic exon coordinates. So rather than exactly matching from the 3' end of the upstream exon to the 5' end of the cryptic exon I should perhaps match splice junctions from the 3' upstream end to any coordinate upstream of the centre of the cryptic coordinate. How about that?
library(optparse)
library(data.table,quietly=T)
library(dplyr)
library(stringr)
library(GenomicRanges,quietly=T)
library(ggplot2)

PSI.threshold <- 0.05
min.canonical.control.SJs <- 5

options(echo=T) 
# For development purposes I will hardcode in the Cleveland TDP mouse inputs.
code="Cleveland_TDP43"
condition.name="CTL_TDP"
support.frame="/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting/support/paper_TDP_mouse_support.tab"
exon.gff="/cluster/scratch3/vyp-scratch2/reference_datasets/RNASeq/Mouse/Mus_musculus.GRCm38.82_fixed.gff"
dexseq.res="/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting/paper_TDP_mouse/Cleveland_TDP43/strict_500/dexseq/CTL_TDP/Cleveland_TDP43_CTL_TDP_SignificantExons.csv"
species="mouse"
condition.names="CTL_TDP"

files.exist <- function(files.list){
	for(my.file in files.list){
		if(!file.exists(my.file)){
			stop(paste(my.file,"doesn't exist!"))
		}
	}
}
files.are.empty <- function(files.list){
	if(length(files.list) == 0){
		stop(paste(files.list,"is empty!"))
	}
	
}


support.frame <- '/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting//F210I_mouse/Fratta_F210I_embryo/splice_junction_analysis/Fratta_F210I_embryo_support_frame.tab' 
code <- 'Fratta_F210I_embryo'
species <- 'mouse' 
condition.names <- 'CTL_HOM' 
dexseq.res <- '/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting//F210I_mouse/Fratta_F210I_embryo/strict_500/dexseq/CTL_HET/Fratta_F210I_embryo_CTL_HET_SignificantExons.csv' 
outFolder <- '/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting//F210I_mouse/Fratta_F210I_embryo/splice_junction_analysis' 


#"--support.frame ${support_frame} --code ${dataset} --condition.names ${condition_names} --dexseq.res ${dexseq_res} --outFolder ${outFolder}" 

## UNCOMMENT THIS!!

option_list <- list(
    make_option(c('--support.frame'), help=''),
    make_option(c('--code'), help=''),
    make_option(c('--condition.names'), help=''),
    make_option(c('--dexseq.res'), help=''),
    make_option(c('--outFolder'), help=''),
    make_option(c('--species'), help='') 
)

########################## read arguments
option.parser <- OptionParser(option_list=option_list)
opt <- parse_args(option.parser)

if(length(opt) > 1){
	support.frame <- opt$support.frame
	code <- opt$code
	condition.names <- opt$condition.names
	dexseq.res <-  opt$dexseq.res
	outFolder <- opt$outFolder
	species <- opt$species
}



if(species=="mouse"){
	annotation <- "/cluster/project8/vyp/vincent/Software/RNASeq_pipeline/bundle/mouse/biomart/biomart_annotations_mouse.tab"
	ling.list <- c("2610507B11Rik",    "A230046K03Rik",	"Adipor2",	"Adnp2",	"Ahnak",	"Atraid",	"Cluh",	"Edem2",	"Ercc6",	"Fam21",	"Fam73a",	"Flnb",	"Ggct",	"Gsta4",	"Gtf2e2",	"Hace1",	"Hgsnat",	"Ift81",	"Lnp",	"Mettl6",	"Mib1",	"Mier1",	"Necap1",	"Nme6",	"Pir",	"Pno1",	"Ppp6c",	"Ptcd2",	"Pycr2",	"Sars",	"Smg5",	"Smg5",	"Snapc3",	"Spata13",	"Spata7",	"Spcs2",	"Sptbn4",	"Sulf1",	"Synj2bp",	"Tecpr1",	"Tnfaip1",	"Tnks2",	"Tnnt1",	"Trim8",	"Uggt2",	"Usp15",	"Usp15",	"Wbscr22",	"Zfp13",	"Zfp809")
	genome.fa <- "/cluster/scratch3/vyp-scratch2/reference_datasets/RNASeq/Mouse/mm10.fa"
}
if(species=="human"){
	annotation <- "/cluster/project8/vyp/vincent/Software/RNASeq_pipeline/bundle/human_hg38/biomart/biomart_annotations_human.tab"
	ling.list <- c("EPB41L4A",    "CEP72",	"INSR",	"FAM114A2",	"PFKP",	"ST5",	"RNFT2",	"RNFT2",	"ALX1",	"AGRN",	"AGRN",	"ATG4B",	"AGRN",	"AGRN",	"ST5",	"SETD5",	"KDELC2",	"MUC16",	"PKN1",	"IRF9",	"UPF2",	"GPSM2",	"XPO4",	"RASA4",	"RASA4B",	"PARP6",	"KRT7",	"TRAPPC12",	"RANBP1",	"HERC6",	"BLZF1",	"ZFP91",	"HDGFRP2",	"MAP3K8",	"SSFA2",	"CENPK",	"ITPR3",	"KYNU",	"IRF9",	"COL4A6",	"KYNU")
#might be wrong
	genome.fa <- "/cluster/scratch3/vyp-scratch2/reference_datasets/human_reference_sequence/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fa "
}
files.exist(c(support.frame,dexseq.res,annotation))
crypt.res <- as.data.frame(fread(dexseq.res))
support <- read.table(support.frame,header=T,stringsAsFactors=F)
support
#gff <- as.data.frame(fread(exon.gff))
#Filter out non-cryptic results and FDR to 0.05
crypt.res <- subset(crypt.res,grepl("i",exonID) & FDR < 0.05)
#Split the exonID to give the intron ID (the same as the upstream exon's ID) and the cryptic ID which isn't useful.
#crypt.res$intronID <- gsub("E",'',str_split_fixed(crypt.res$exonID, "i", 2)[,1])
#crypt.res$cryptID <- str_split_fixed(crypt.res$exonID, "i", 2)[,2]

#GFF - parse the information in V9
#str_trim removes leading whitespace, gsub removes quotes
#gff$EnsemblID <- str_trim(gsub('\"', '', gsub('\"','',str_split_fixed(gff$V9,"gene_id",2)[,2])))
#gff$exonID <- gsub(';', '', gsub('\"','',str_split_fixed(gff$V9," ",6)[,4]))

#Match the upstream exon coordinates
#crypt.res$upstream.exon.start <- gff$V4[match(paste(crypt.res$EnsemblID,crypt.res$intronID),paste(gff$EnsemblID,gff$exonID))]
#crypt.res$upstream.exon.end <- gff$V5[match(paste(crypt.res$EnsemblID,crypt.res$intronID),paste(gff$EnsemblID,gff$exonID))]
#now the downstream. This is intronID + 1. I can get away with this with as.numeric()
#crypt.res$downstream.exon.start <- gff$V4[match(paste(crypt.res$EnsemblID,as.numeric(crypt.res$intronID) + 1),paste(gff$EnsemblID,as.numeric(gff$exonID)))]
#crypt.res$downstream.exon.end <- gff$V5[match(paste(crypt.res$EnsemblID,as.numeric(crypt.res$intronID) + 1),paste(gff$EnsemblID,as.numeric(gff$exonID)))]

#Now find the splice junction files. Use the condition variable which is generated by DEXSeq from the conditions in the support. So WT vs HET becomes WT_HET. This tells you which condition is set as the reference.
# I often use underscores as a delimiter in condition names so this has to be able to put up with that. Split the condition variable on the underscore into a maximum of six pieces.
condition.list <- str_split_fixed(condition.names,"_",6)
# create a list of possible control/wildtype condition names. Should be exhaustive. A bad strategy.
control.list <- c("Ctl","Ctrl","ctl","CTL","CONTROL","Control","control","WT","wt","wildtype","Wildtype","Wild-type","CTRL","ctrl")
#  subset the support file to just the lines where the condition equals one of the control.list entries. This gives you the location of the bam file. This assumes that STAR has been used to align and has output a list of splice junctions.
control_SJ_list <- gsub('_unique.bam','SJ.out.tab',subset(support,dataset==code & support[,4] %in% control.list)$bam)
control_SJ_list
flipped <- FALSE
# If the controls don't come first then the log2FoldChange needs to be flipped around. Affects all subsequent analysis so quite important!
if(!condition.list[1] %in% control.list & !flipped){
	message("The control and case labels are probably flipped round. Flipping round the log2FoldChange sign to compensate.")
	flipped <- TRUE
	crypt.res$log2FoldChange <- as.numeric(crypt.res$log2FoldChange) * -1
}

case.list <- condition.list[!condition.list %in% control.list]
#here's a stupid fudge that will probably only work for one exception:
# assuming that the control condition had no underscores and has been properly identified then the remaining conditions in the case.list all belong to the same condition that were orignally delimited by an underscore. 
# remove the empty strings from the list and stick the pieces back together with collapse="_". 
case.list <- paste(case.list[case.list != ""],collapse="_")
case_SJ_list <- gsub('_unique.bam','SJ.out.tab',subset(support,dataset==code & support[,4] %in% case.list)$bam)
case_SJ_list

files.exist(c(case_SJ_list,control_SJ_list))

debugRdata <- paste0(outFolder, "/", code, "_", condition.names, "_splicing_analysis_DEBUG.Rdata")
save.image(debugRdata)
# Need some kind of for loop to iterate through each splice junction list. practice first on one.
#column 7 of the SJ.tab file is the number of uniquely mapping splice junctions.
# This assumes a canonical splice junction that matches exactly the downstream 3' and upstream 5' nearest exons in the GFF. 
# Only half of the test dataset's results have these junctions. It could be due to the nearest exon is not expressed.
# How to deal with this? Something more relaxed the junction has to be at least the size of the downstream and upstream nearest but maybe not.
#crypt.res$canonical.SJ <- SJtdp_5$V7[match(paste(as.numeric(crypt.res$upstream.exon.end) + 1 ,as.numeric(crypt.res$downstream.exon.start) - 1),paste(SJtdp_5$V2,SJtdp_5$V3))]



#==============
## New Strategy
#==============
# Each cryptic exon sits within an intron but the start and end of that intron cannot be inferred from the GFF file alone. Instead the canonical junction should be the junction that falls outside of the cryptic exons's coordinates with the most junction reads. 

# This function reads in all the SJ.tab files given in the list and merges them all together to give a list of unique SJs with total numbers of occurences across all the datasets in the list.
merge.SJ.files <- function(SJ.tab.list){
	# First read in all the files in the list
	SJ.file.list <- list()
	for(i in 1:length(SJ.tab.list)){
        	SJ <- as.data.frame(fread(SJ.tab.list[i]))
        	SJ.file.list[[i]] <- SJ
        }
	# rbind all together
	SJ.merge <- rbindlist(SJ.file.list)
	SJ.merge <- as.data.frame(SJ.merge)
	#Use dplyr to group the total list of splice junctions by unique SJ and then sum the total of the cases.
	by_coord <- group_by(SJ.merge, paste(V1,V2,V3))
	SJ.summary <- summarise(by_coord,
        	count.unique = sum(V7),
        	count.multi = sum(V8),
        	strand = mean(V4),
			intron.motif = mean(V5)
        	)
	names(SJ.summary)[1] <- "coord"
	#split the coordinate reference into columns
	SJ.summary$chr <- str_split_fixed(SJ.summary$coord, " ", 3)[,1]
	SJ.summary$start <- str_split_fixed(SJ.summary$coord, " ", 3)[,2]
	SJ.summary$end <- str_split_fixed(SJ.summary$coord, " ", 3)[,3]
	#this is where columns are dropped?
	SJ.summary <- SJ.summary[,c(6,7,8,2,3,4,5)]
	SJ.summary <- as.data.frame(SJ.summary)
	SJ.summary$start <- as.numeric(SJ.summary$start)
	SJ.summary$end <- as.numeric(SJ.summary$end)
	# make strand readable
	SJ.summary[SJ.summary$strand == 1,]$strand <- "+"
	SJ.summary[SJ.summary$strand == 2,]$strand <- "-"
    SJ.summary[SJ.summary$strand == 0,]$strand <- "*"
    #make intron motif readable
	motif.list <- c("non-canonical","GT/AG","CT/AC","GC/AG","CT/GC","AT/AC","GT/AT")
	for(i in 1:7){
		if(length(SJ.summary[SJ.summary$intron.motif == (i - 1),]$intron.motif) > 0){
			SJ.summary[SJ.summary$intron.motif == (i - 1),]$intron.motif <- motif.list[i]
		} 
	}
	#unique SJs will become "score" field in GRanges object
	names(SJ.summary)[4] <- "score"
	return(SJ.summary)
}

#this function below allows you to specify which GRange object to query
canonical_junction_query <- function(CE.chr,CE.start,CE.end, SJ.GRange){
        junction <- SJ.GRange[seqnames(SJ.GRange)==CE.chr & start(SJ.GRange) <= as.numeric(CE.start)+1 & end(SJ.GRange) >= as.numeric(CE.end)-1]
        junction <- head(junction[order(score(junction),decreasing=T)],1)
        return(junction)
}
# this function looks for junctions in the case dataset that exactly match those discovered in the control dataset.
canonical_junction_replication <- function(CE.chr,canonical.start,canonical.end,SJ.GRange){
	junction <- SJ.GRange[seqnames(SJ.GRange) == CE.chr & start(SJ.GRange) == as.numeric(canonical.start) & end(SJ.GRange) == as.numeric(canonical.end)]
	return(junction)
}

#this function looks for SJs that span from the upstream end of the canonical intron to the 5' end of the cryptic exon. Only the most abundant SJ will be reported.
#does this have to be canonical.start or canonical.start +1?
upstream_junction_query <- function(CE.chr,CE.start,CE.end,canonical.start,SJ.GRange){
	junction <- SJ.GRange[seqnames(SJ.GRange) == CE.chr & start(SJ.GRange) == as.numeric(canonical.start) & end(SJ.GRange) >= as.numeric(CE.start) - 1 & end(SJ.GRange) < as.numeric(CE.end)]
	junction <- head(junction[order(score(junction),decreasing=T)],1)
    return(junction)
}

downstream_junction_query <- function(CE.chr,CE.start,CE.end,canonical.end,SJ.GRange){
	junction <- SJ.GRange[seqnames(SJ.GRange) == CE.chr & start(SJ.GRange) > as.numeric(CE.start) & start(SJ.GRange) <= as.numeric(CE.end) + 1 & end(SJ.GRange) == as.numeric(canonical.end)]
	junction <- head(junction[order(score(junction),decreasing=T)],1)
    return(junction)
}
#applying the above function to each cryptic exon and cleaning up the result


canonical_junction_detector <- function(SJ.summary,results.df,mode="discovery"){
	GRanges_object <-  makeGRangesFromDataFrame(SJ.summary,keep.extra.columns=T)
	if(mode == "discovery"){
		junctions.list <- apply(results.df, MAR=1,FUN=function(x) canonical_junction_query(x[10],x[11],x[12], GRanges_object))
		}
	if(mode == "replication"){
		junctions.list <- apply(results.df, MAR=1,FUN=function(x) canonical_junction_replication(x[10],x[15],x[16], GRanges_object))	
	}
	#output is a list of GRange objects - unuseable.
	junctions.list <- unlist(GRangesList(junctions.list))
	#convert into a dataframe, extracting the relevent information from the GRanges object.
	#names(GRanges) is a vector of rownames, confusingly.
	canonical.df <- data.frame(row.names=names(junctions.list),
			canonical.chr=seqnames(junctions.list),
			canonical.start=start(junctions.list),
			canonical.end=end(junctions.list),
			canonical.unique.count = score(junctions.list),
			canonical.strand = strand(junctions.list),
			intron.motif = mcols(junctions.list)[3])
	return(canonical.df)
}

# need to find the counts of canonical junctions that were assigned by canonical_junction_detector in the case dataset.

#This function assumes that the results file has been appended with the canonical start and end coordinates at positions ??? and ??? respectively.
bridging_junction_finder <- function(SJ.summary, results.df, query.type){
	GRanges_object <-  makeGRangesFromDataFrame(SJ.summary,keep.extra.columns=T)
	if(query.type == "downstream"){
		junctions.list <- apply(results.df, MAR=1,FUN=function(x) downstream_junction_query(x[10],x[11],x[12], x[16], GRanges_object))
	}
	if(query.type == "upstream"){
		junctions.list <- apply(results.df, MAR=1,FUN=function(x) upstream_junction_query(x[10],x[11],x[12], x[15], GRanges_object))
	}
	#output is a list of GRange objects - unuseable.
	junctions.list <- unlist(GRangesList(junctions.list))
	#convert into a dataframe, extracting the relevent information from the GRanges object.
	#names(GRanges) is a vector of rownames, confusingly.
	if(query.type == "downstream"){
		bridging_junctions.df <- data.frame(row.names=names(junctions.list),
			chr=seqnames(junctions.list),
			cryptic.3prime=start(junctions.list),
			canonical.end=end(junctions.list),
			downstream.unique.count = score(junctions.list),
			downstream.strand = strand(junctions.list),
			intron.motif = mcols(junctions.list)[3])
	}
	if(query.type == "upstream"){
		bridging_junctions.df <- data.frame(row.names=names(junctions.list),
			chr=seqnames(junctions.list),
			canonical.start=start(junctions.list),
			cryptic.5prime=end(junctions.list),
			upstream.unique.count = score(junctions.list),
			upstream.strand = strand(junctions.list),
			intron.motif = mcols(junctions.list)[3])
	}
	return(bridging_junctions.df)
}


fix.gene.names <- function(results.df,annotation){
	# This is a function to find the most likely gene name for a given genomic range.
	# If multiple genes overlap the query range then output the names appended together with "+".
	# Get the strand information as well. If multiple genes are returned and their strands agree then output that strand.
	# If multiple genes are returned and the strands do not agree then output NA.
	gene.names.query <- function(chromosome, canonical.start, canonical.end, anno.GRange){
		gene.name <- anno.GRange[seqnames(anno.GRange) == chromosome & start(anno.GRange) <= as.numeric(canonical.start) & end(anno.GRange) >= as.numeric(canonical.end)]
		#if multiple gene names come up then collapse all the gene names into one string separated by "+".
		if(length(gene.name) > 1){
			mcols(gene.name)[,2] <- paste(mcols(gene.name)[,2],collapse="+")	
		# and strand as well!
		# if the different genes have differing strands then assign strand as NA.
			if(length(unique(as.list(strand(gene.name)))) != 1){
				strand(gene.name) <- NA
			}
			gene.name <- gene.name[1]
		}
		return(gene.name)
	}
	annotation <- as.data.frame(fread(annotation,header=T,stringsAsFactors=F))
	#sort out annotation and turn into a GRanges object. remove gm genes
	names(annotation)[4:5] <- c("start","end")
	anno.GRange<-  makeGRangesFromDataFrame(annotation,keep.extra.columns=T)
	fixed.gene.names <- apply(results.df, MAR=1,FUN=function(x) gene.names.query(x[10],x[15],x[16],anno.GRange)) 
	fixed.gene.names <- unlist(GRangesList(fixed.gene.names))
	fixed.gene.names <- data.frame(row.names=names(fixed.gene.names),gene <- mcols(fixed.gene.names)[,2], fixed.strand=strand(fixed.gene.names))
	names(fixed.gene.names)[1] <- "fixed.gene.id"
	#fixed.gene.names$fixed.strand <- gsub("+","1",fixed.gene.names$fixed.strand,fixed=T)
	#fixed.gene.names$fixed.strand <- gsub("-","-1",fixed.gene.names$fixed.strand,fixed=T)
	return(fixed.gene.names)
}

# Classify the results
# Each dexseq result has now been annotated with information about the intron in which it occurs, the splice junctions from the start and end of the intron into the cryptic site itself, plus whether the splice junctions use the canonical splice site nucleotides. 
# Classifying a cryptic exon: 
	# Log2FoldChange can be relaxed to around 0.5 due to intronic noise 
	# At least 1 upstream and/or 1 downstream splice junction per dataset
	# the ratio of cryptic splicing must be higher in the same direcition as the log2FoldChange
# Classifying a retained intron:
	# log2FoldChange must be at least 1
	# there should be a reduction of canonical splicing in the same direction as the log2FoldChange

# A new version of the cryptic classifier allocates names that are less ambiguous.

cryptic.classifier <- function(crypt.counts){
	classer <- function(subset.df,classification){
		if(dim(subset.df)[1] > 0){
			subset.df$class <- classification
			return(subset.df$class)
		}
	}
	# Classify the tags with small fold changes or low read depths
	FEW.READS.UP <- subset(crypt.counts, (as.numeric(log2FoldChange)) > 0  & meanBase < 3.3)
	FEW.READS.UP$class <- classer(FEW.READS.UP,"FEW.READS.UP")

	FEW.READS.DOWN <- subset(crypt.counts, (as.numeric(log2FoldChange)) < 0  & meanBase < 3.3)
	FEW.READS.DOWN$class <- classer(FEW.READS.DOWN,"FEW.READS.DOWN")

	SMALL.FOLDCHANGE.UP <- subset(crypt.counts, as.numeric(log2FoldChange) < 0.6 & as.numeric(log2FoldChange) > 0 )
	SMALL.FOLDCHANGE.UP$class <- classer(SMALL.FOLDCHANGE.UP, "SMALL.FOLDCHANGE.UP")

	SMALL.FOLDCHANGE.DOWN <- subset(crypt.counts, as.numeric(log2FoldChange) > -0.6 & as.numeric(log2FoldChange) < 0 )
	SMALL.FOLDCHANGE.DOWN$class <- classer(SMALL.FOLDCHANGE.DOWN, "SMALL.FOLDCHANGE.DOWN")
	
	CLEAN.UP <- subset(crypt.counts, as.numeric(log2FoldChange) >= 0.6  & meanBase >= 3.3)
	
	SJ.UNSUPPORTED.UP <- subset(CLEAN.UP,
		(CLEAN.UP$upstream.case.mean.SJ < 1 &
		CLEAN.UP$downstream.case.mean.SJ < 1 ) | 
		CLEAN.UP$PSI.class == "TOO.SMALL.PSI" )
	SJ.UNSUPPORTED.UP$class <- classer(SJ.UNSUPPORTED.UP,"SJ.UNSUPPORTED.UP")

	SJ.SUPPORTED.UP <- subset(CLEAN.UP,
		(CLEAN.UP$upstream.case.mean.SJ >= 1 |
		CLEAN.UP$downstream.case.mean.SJ >= 1) &
		CLEAN.UP$PSI.class != "TOO.SMALL.PSI" )
	SJ.SUPPORTED.UP$class <- classer(SJ.SUPPORTED.UP,"SJ.SUPPORTED.UP")
	
	CLEAN.DOWN <- subset(crypt.counts, as.numeric(log2FoldChange) <= -0.6 & meanBase >= 3.3)
	SJ.UNSUPPORTED.DOWN <- subset(CLEAN.DOWN,
	  ( CLEAN.DOWN$upstream.case.mean.SJ < 1 &
		CLEAN.DOWN$downstream.case.mean.SJ < 1 ) |
		CLEAN.DOWN$PSI.class == "TOO.SMALL.PSI" )
	SJ.UNSUPPORTED.DOWN$class <- classer(SJ.UNSUPPORTED.DOWN,"SJ.UNSUPPORTED.DOWN")

	SJ.SUPPORTED.DOWN <- subset(CLEAN.DOWN,
		(CLEAN.DOWN$upstream.case.mean.SJ >= 1 |
		CLEAN.DOWN$downstream.case.mean.SJ >= 1) &
		CLEAN.DOWN$PSI.class != "TOO.SMALL.PSI" )
	SJ.SUPPORTED.DOWN$class <- classer(SJ.SUPPORTED.DOWN,"SJ.SUPPORTED.DOWN")

	crypt.counts.classified <- rbind(SJ.SUPPORTED.UP,SJ.SUPPORTED.DOWN,SJ.UNSUPPORTED.UP,SJ.UNSUPPORTED.DOWN,SMALL.FOLDCHANGE.UP,SMALL.FOLDCHANGE.DOWN,FEW.READS.UP,FEW.READS.DOWN)

	return(crypt.counts.classified)
}


# canonical.control.mean.SJ instead of meanBase
cryptic.classifier <- function(crypt.counts){
	classer <- function(subset.df,classification){
		if(dim(subset.df)[1] > 0){
			subset.df$class <- classification
			return(subset.df$class)
		}
	}
	# Classify the tags with small fold changes or low read depths
	FEW.READS.UP <- subset(crypt.counts, (as.numeric(log2FoldChange)) > 0  & canonical.control.mean.SJ < min.canonical.control.SJs )
	FEW.READS.UP$class <- classer(FEW.READS.UP,"FEW.READS.UP")

	FEW.READS.DOWN <- subset(crypt.counts, (as.numeric(log2FoldChange)) < 0  & canonical.control.mean.SJ < min.canonical.control.SJs )
	FEW.READS.DOWN$class <- classer(FEW.READS.DOWN,"FEW.READS.DOWN")

	SMALL.FOLDCHANGE.UP <- subset(crypt.counts, as.numeric(log2FoldChange) < 0.6 & as.numeric(log2FoldChange) > 0 )
	SMALL.FOLDCHANGE.UP$class <- classer(SMALL.FOLDCHANGE.UP, "SMALL.FOLDCHANGE.UP")

	SMALL.FOLDCHANGE.DOWN <- subset(crypt.counts, as.numeric(log2FoldChange) > -0.6 & as.numeric(log2FoldChange) < 0 )
	SMALL.FOLDCHANGE.DOWN$class <- classer(SMALL.FOLDCHANGE.DOWN, "SMALL.FOLDCHANGE.DOWN")
	
	CLEAN.UP <- subset(crypt.counts, as.numeric(log2FoldChange) >= 0.6  & canonical.control.mean.SJ >= min.canonical.control.SJs )
	
	SJ.UNSUPPORTED.UP <- subset(CLEAN.UP,
		(CLEAN.UP$upstream.case.mean.SJ < 1 &
		CLEAN.UP$downstream.case.mean.SJ < 1 ) | 
		CLEAN.UP$PSI.class == "TOO.SMALL.PSI" )
	SJ.UNSUPPORTED.UP$class <- classer(SJ.UNSUPPORTED.UP,"SJ.UNSUPPORTED.UP")

	SJ.SUPPORTED.UP <- subset(CLEAN.UP,
		(CLEAN.UP$upstream.case.mean.SJ >= 1 |
		CLEAN.UP$downstream.case.mean.SJ >= 1) &
		CLEAN.UP$PSI.class != "TOO.SMALL.PSI" )
	SJ.SUPPORTED.UP$class <- classer(SJ.SUPPORTED.UP,"SJ.SUPPORTED.UP")
	
	CLEAN.DOWN <- subset(crypt.counts, as.numeric(log2FoldChange) <= -0.6 & canonical.control.mean.SJ >= min.canonical.control.SJs )
	SJ.UNSUPPORTED.DOWN <- subset(CLEAN.DOWN,
	  ( CLEAN.DOWN$upstream.case.mean.SJ < 1 &
		CLEAN.DOWN$downstream.case.mean.SJ < 1 ) |
		CLEAN.DOWN$PSI.class == "TOO.SMALL.PSI" )
	SJ.UNSUPPORTED.DOWN$class <- classer(SJ.UNSUPPORTED.DOWN,"SJ.UNSUPPORTED.DOWN")

	SJ.SUPPORTED.DOWN <- subset(CLEAN.DOWN,
		(CLEAN.DOWN$upstream.case.mean.SJ >= 1 |
		CLEAN.DOWN$downstream.case.mean.SJ >= 1) &
		CLEAN.DOWN$PSI.class != "TOO.SMALL.PSI" )
	SJ.SUPPORTED.DOWN$class <- classer(SJ.SUPPORTED.DOWN,"SJ.SUPPORTED.DOWN")

	crypt.counts.classified <- rbind(SJ.SUPPORTED.UP,SJ.SUPPORTED.DOWN,SJ.UNSUPPORTED.UP,SJ.UNSUPPORTED.DOWN,SMALL.FOLDCHANGE.UP,SMALL.FOLDCHANGE.DOWN,FEW.READS.UP,FEW.READS.DOWN)

	return(crypt.counts.classified)
}


cryptic.PSI.classifier <- function(cryptic.exons){
  classer <- function(subset.df,classification){
    if(dim(subset.df)[1] > 0){
      subset.df$class <- classification
      return(subset.df$class)
    }
  }
# Classify the tags with small fold changes or low read depths

  FIVEPRIME.BIAS <- subset(cryptic.exons, (as.numeric(upstream_delta_psi) >= PSI.threshold) & (as.numeric(downstream_delta_psi) < PSI.threshold) )
  FIVEPRIME.BIAS$PSI.class <- classer(FIVEPRIME.BIAS,"FIVEPRIME.BIAS")
  
  THREEPRIME.BIAS <- subset(cryptic.exons, (as.numeric(upstream_delta_psi) < PSI.threshold) & (as.numeric(downstream_delta_psi) >= PSI.threshold) )
  THREEPRIME.BIAS$PSI.class <- classer(THREEPRIME.BIAS,"THREEPRIME.BIAS")
  
  CASSETTE.LIKE <- subset(cryptic.exons, (as.numeric(upstream_delta_psi) >= PSI.threshold ) & (as.numeric(downstream_delta_psi) >= PSI.threshold) )
  CASSETTE.LIKE$PSI.class <- classer(CASSETTE.LIKE,"CASSETTE.LIKE")
  
  TOO.SMALL.PSI <- subset(cryptic.exons, (as.numeric(upstream_delta_psi) <= PSI.threshold )& (as.numeric(downstream_delta_psi) <= PSI.threshold) )
  TOO.SMALL.PSI$PSI.class <- classer(TOO.SMALL.PSI,"TOO.SMALL.PSI")
  
  cryptic.exons.PSI.classified <- rbind(FIVEPRIME.BIAS,THREEPRIME.BIAS,CASSETTE.LIKE,TOO.SMALL.PSI)
  return(cryptic.exons.PSI.classified)
}

# A third version which only cares about SJ information

# #cryptic.classifier <- function(crypt.counts){
# 	# classer <- function(subset.df,classification){
# 	# 	if(dim(subset.df)[1] > 0){
# 	# 		subset.df$class <- classification
# 	# 		return(subset.df$class)
# 	# 	}
# 	# }
# 
# 
# 	# Classify the tags with small fold changes or low read depths	
# 	CLEAN.UP <- subset(crypt.counts, as.numeric(log2FoldChange) >= 0  & meanBase >= 0)
# 	
# 	SJ.UNSUPPORTED.UP <- subset(CLEAN.UP,
# 		CLEAN.UP$upstream.case.mean.SJ < 1 &
# 		CLEAN.UP$downstream.case.mean.SJ < 1 )
# 	SJ.UNSUPPORTED.UP$class <- classer(SJ.UNSUPPORTED.UP,"SJ.UNSUPPORTED.UP")
# 
# 	SJ.SUPPORTED.UP <- subset(CLEAN.UP,
# 		CLEAN.UP$upstream.case.mean.SJ >= 1 |
# 		CLEAN.UP$downstream.case.mean.SJ >= 1 )
# 	SJ.SUPPORTED.UP$class <- classer(SJ.SUPPORTED.UP,"SJ.SUPPORTED.UP")
# 	
# 	CLEAN.DOWN <- subset(crypt.counts, as.numeric(log2FoldChange) <= 0 & meanBase >= 0)
# 	SJ.UNSUPPORTED.DOWN <- subset(CLEAN.DOWN,
# 		CLEAN.DOWN$upstream.case.mean.SJ < 1 &
# 		CLEAN.DOWN$downstream.case.mean.SJ < 1 )
# 	SJ.UNSUPPORTED.DOWN$class <- classer(SJ.UNSUPPORTED.DOWN,"SJ.UNSUPPORTED.DOWN")
# 
# 	SJ.SUPPORTED.DOWN <- subset(CLEAN.DOWN,
# 		CLEAN.DOWN$upstream.case.mean.SJ >= 1 |
# 		CLEAN.DOWN$downstream.case.mean.SJ >= 1 )
# 	SJ.SUPPORTED.DOWN$class <- classer(SJ.SUPPORTED.DOWN,"SJ.SUPPORTED.DOWN")
# 
# 	crypt.counts.classified <- rbind(SJ.SUPPORTED.UP,SJ.SUPPORTED.DOWN,SJ.UNSUPPORTED.UP,SJ.UNSUPPORTED.DOWN)
# 	return(crypt.counts.classified)
# }


#cbind won't work as there are a few cryptic intervals that apparently lack canonical splice junctions. Intriguing. Match instead on rownames

#Now I have a results table where each result has a canonical splice site within which the cryptic exon sits. I need to now trawl through each SJ.tab file separately to find:
# 1) The number of splice junctions that span the canonical intron.
# 2) The number of splice junctions that span between the 5' end of the canonical intron and the middle of the cryptic exon.
# 3) The number of splice junctions that span between the middle of the cryptic exon and the 3' end of the canonical intron. 
# This will be super time-consuming as I now have to query each SJ.tab file 3 times for each result.
# Unless I just output total counts for each condition. I could repeat the same dplyr script (or Bedtools to speed things up) to merge together the knockdown SJ.tab files.
# To anticipate datasets where the n of cases and controls is differerent I could just output a mean.
# This would mean querying SJ.tab files 6 times rather than 6n times.
#crypt.res <- head(crypt.res,100)


# CANONICAL SPLICING IN CONTROLS

control_total_SJ_counts <- merge.SJ.files(control_SJ_list)
control_SJs.out <- paste0(outFolder,"/",code,"_SJs_control.tab")
write.table(control_total_SJ_counts, control_SJs.out, quote=F,sep="\t",row.names=F)

canonical_results_control <- canonical_junction_detector(SJ.summary = control_total_SJ_counts, 
														 results.df = crypt.res, 
														 mode = "discovery")

# canonical coordinates added to results
crypt.res$canonical.chr <- canonical_results_control$canonical.chr[match(rownames(crypt.res),rownames(canonical_results_control))]
crypt.res$canonical.start <- canonical_results_control$canonical.start[match(rownames(crypt.res),rownames(canonical_results_control))]
crypt.res$canonical.end <- canonical_results_control$canonical.end[match(rownames(crypt.res),rownames(canonical_results_control))]
crypt.res$canonical.strand <- canonical_results_control$canonical.strand[match(rownames(crypt.res),rownames(canonical_results_control))]
crypt.res$canonical.intron.motif <- canonical_results_control$intron.motif[match(rownames(crypt.res),rownames(canonical_results_control))]
crypt.res$canonical.control.mean.SJ <- canonical_results_control$canonical.unique.count[match(rownames(crypt.res),rownames(canonical_results_control))]
crypt.res$canonical.control.mean.SJ <- crypt.res$canonical.control.mean.SJ / length(control_SJ_list)
# remove NA values from canonical junctions. In some cases there is no canonical junction to be found. Why?
crypt.res <- subset(crypt.res,!is.na(crypt.res$canonical.start))

# upstream junctions in control
upstream_results_control <- bridging_junction_finder(SJ.summary = control_total_SJ_counts,
													 results.df = crypt.res,
													 query.type = "upstream")
crypt.res$upstream.control.canonical.start <- upstream_results_control$canonical.start[match(rownames(crypt.res),rownames(upstream_results_control))]
crypt.res$upstream.control.cryptic.5prime <- upstream_results_control$cryptic.5prime[match(rownames(crypt.res),rownames(upstream_results_control))]
crypt.res$upstream.control.strand <- upstream_results_control$upstream.strand[match(rownames(crypt.res),rownames(upstream_results_control))]
crypt.res$upstream.control.intron.motif <- upstream_results_control$intron.motif[match(rownames(crypt.res),rownames(upstream_results_control))]
crypt.res$upstream.control.mean.SJ <- upstream_results_control$upstream.unique.count[match(rownames(crypt.res),rownames(upstream_results_control))]
crypt.res$upstream.control.mean.SJ <- crypt.res$upstream.control.mean.SJ / length(control_SJ_list)

# downstream junctions in control
downstream_results_control <- bridging_junction_finder(SJ.summary = control_total_SJ_counts, 
													   results.df = crypt.res, 
													   query.type = "downstream")
crypt.res$downstream.control.cryptic.3prime <- downstream_results_control$cryptic.3prime[match(rownames(crypt.res),rownames(downstream_results_control))]
crypt.res$downstream.control.canonical.end <- downstream_results_control$canonical.end[match(rownames(crypt.res),rownames(downstream_results_control))]
crypt.res$downstream.control.strand <- downstream_results_control$downstream.strand[match(rownames(crypt.res),rownames(downstream_results_control))]
crypt.res$downstream.control.intron.motif <- downstream_results_control$intron.motif[match(rownames(crypt.res),rownames(downstream_results_control))]
crypt.res$downstream.control.mean.SJ <- downstream_results_control$downstream.unique.count[match(rownames(crypt.res),rownames(downstream_results_control))]
crypt.res$downstream.control.mean.SJ <- crypt.res$downstream.control.mean.SJ / length(control_SJ_list)

# CANONICAL SPLICING IN CASES - COUNT SJs AT SAME POSITION AS CONTROLS
case_total_SJ_counts <- merge.SJ.files(case_SJ_list)
case_SJs.out <- paste0(outFolder,"/",code,"_SJs_case.tab")
write.table(case_total_SJ_counts, case_SJs.out, quote=F,sep="\t",row.names=F)

canonical_results_case <- canonical_junction_detector(SJ.summary = case_total_SJ_counts, 
													  results.df = crypt.res, 
													  mode = "replication")
# Add numbers of canonical splicing in cases to results
crypt.res$canonical.case.mean.SJ <- canonical_results_case$canonical.unique.count[match(rownames(crypt.res),rownames(canonical_results_case))]
crypt.res$canonical.case.mean.SJ <- crypt.res$canonical.case.mean.SJ / length(control_SJ_list)

# upstream junctions in cases
upstream_results_case <- bridging_junction_finder(SJ.summary = case_total_SJ_counts, 
												  results.df = crypt.res, 
												  query.type = "upstream")
crypt.res$upstream.case.canonical.start <- upstream_results_case$canonical.start[match(rownames(crypt.res),rownames(upstream_results_case))]
crypt.res$upstream.case.cryptic.5prime <- upstream_results_case$cryptic.5prime[match(rownames(crypt.res),rownames(upstream_results_case))]
crypt.res$upstream.case.strand <- upstream_results_case$upstream.strand[match(rownames(crypt.res),rownames(upstream_results_case))]
crypt.res$upstream.case.intron.motif <- upstream_results_case$intron.motif[match(rownames(crypt.res),rownames(upstream_results_case))]

crypt.res$upstream.case.mean.SJ <- upstream_results_case$upstream.unique.count[match(rownames(crypt.res),rownames(upstream_results_case))]
crypt.res$upstream.case.mean.SJ <- crypt.res$upstream.case.mean.SJ / length(case_SJ_list)

# downstream junctions in cases
downstream_results_case <- bridging_junction_finder(SJ.summary = case_total_SJ_counts, 
													results.df = crypt.res, 
													query.type = "downstream")
crypt.res$downstream.case.cryptic.3prime <- downstream_results_case$cryptic.3prime[match(rownames(crypt.res),rownames(downstream_results_case))]
crypt.res$downstream.case.canonical.end <- downstream_results_case$canonical.end[match(rownames(crypt.res),rownames(downstream_results_case))]
crypt.res$downstream.case.strand <- downstream_results_case$downstream.strand[match(rownames(crypt.res),rownames(downstream_results_case))]
crypt.res$downstream.case.intron.motif <- downstream_results_case$intron.motif[match(rownames(crypt.res),rownames(downstream_results_case))]
crypt.res$downstream.case.mean.SJ <- downstream_results_case$downstream.unique.count[match(rownames(crypt.res),rownames(downstream_results_case))]
crypt.res$downstream.case.mean.SJ <- crypt.res$downstream.case.mean.SJ / length(case_SJ_list)

# create ratios of cryptic to canonical splicing
#convert all NAs to zeros
crypt.res[is.na(crypt.res)] <- "0"
crypt.res[,c(19,24,29,30,35,40)] <- as.numeric(unlist(crypt.res[,c(19,24,29,30,35,40)]))

crypt.res$control.upstream.ratio <- crypt.res$upstream.control.mean.SJ / crypt.res$canonical.control.mean.SJ
crypt.res$control.downstream.ratio <- crypt.res$downstream.control.mean.SJ / crypt.res$canonical.control.mean.SJ

crypt.res$case.upstream.ratio <- crypt.res$upstream.case.mean.SJ / crypt.res$canonical.case.mean.SJ
crypt.res$case.downstream.ratio <- crypt.res$downstream.case.mean.SJ / crypt.res$canonical.case.mean.SJ

#fix the gene names using annotation. If gene name still cannot be resolved then throw out.
fixed.gene.names <- fix.gene.names(crypt.res,annotation)
crypt.res$fix.gene.names <- as.character(fixed.gene.names$fixed.gene.id[match(row.names(crypt.res),row.names(fixed.gene.names))])
crypt.res$fix.gene.names <- ifelse(test = is.na(crypt.res$fix.gene.names),yes = crypt.res$external_gene_id,no = crypt.res$fix.gene.names)
crypt.res$fix.strand <- as.character(fixed.gene.names$fixed.strand[match(row.names(crypt.res),row.names(fixed.gene.names))])
crypt.res$fix.strand <- ifelse(test=is.na(crypt.res$fix.strand),yes=crypt.res$strand,no=as.character(crypt.res$fix.strand))
crypt.res <- subset(crypt.res, !is.na(crypt.res$fix.gene.names))

# add percent ratios of changes in upstream and downstream SJs for more summarising
crypt.res$upstream_delta_psi <- ifelse(crypt.res$fix.strand == "+",
      yes = (crypt.res$upstream.case.mean.SJ / (crypt.res$upstream.case.mean.SJ + crypt.res$canonical.case.mean.SJ) )  - (crypt.res$upstream.control.mean.SJ / (crypt.res$upstream.control.mean.SJ + crypt.res$canonical.control.mean.SJ) ),
      no = (crypt.res$downstream.case.mean.SJ / (crypt.res$downstream.case.mean.SJ + crypt.res$canonical.case.mean.SJ) ) - (crypt.res$downstream.control.mean.SJ / (crypt.res$downstream.control.mean.SJ + crypt.res$canonical.control.mean.SJ) ) )
crypt.res$downstream_delta_psi <- ifelse(crypt.res$fix.strand == "+",
      yes = (crypt.res$downstream.case.mean.SJ / (crypt.res$downstream.case.mean.SJ + crypt.res$canonical.case.mean.SJ) ) - (crypt.res$downstream.control.mean.SJ / (crypt.res$downstream.control.mean.SJ + crypt.res$canonical.control.mean.SJ) ), 
      no =  (crypt.res$upstream.case.mean.SJ / (crypt.res$upstream.case.mean.SJ + crypt.res$canonical.case.mean.SJ) )  - (crypt.res$upstream.control.mean.SJ / (crypt.res$upstream.control.mean.SJ + crypt.res$canonical.control.mean.SJ) ) )
crypt.res <- crypt.res[crypt.res$FDR < 0.05,]

# apply delta PSI classification
crypt.res <- cryptic.PSI.classifier(crypt.res)

# apply classification function
crypt.res.classified <- cryptic.classifier(crypt.res)

crypt.res.classified <- subset(crypt.res.classified, !is.na(class))
# for graphing, slice out whether it is cryptic exon, intron retention, possible or noise.
crypt.res.classified$family <- str_split_fixed(crypt.res.classified$class, pattern = "[.]UP|[.]DOWN",3)[,1]

crypt.res.classified$in.Ling <- ling.list[match(crypt.res.classified$fix.gene.names,ling.list)]

graph1 <- paste0(outFolder, "/", code, "_", condition.names, "_classification.pdf")
graph1.5 <- paste0(outFolder, "/", code, "_", condition.names, "_classification_counts.pdf")
graph2 <- paste0(outFolder, "/", code, "_", condition.names, "_splice_junctions.pdf")
title.code <- code
if(grepl("Cleveland_TDP43", code)){
title.code <- "Polymenidou_et al_2011_TDP43_knockdown"
}
if(grepl("Chiang",code)){
  title.code <- "Chiang_et_al_2010_TDP43_deletion"
}
if(grepl("dataset",code)){
  title.code <- paste("ENCODE_K562_TDP43_knockdown", code,sep="_")
}

graph_title <- paste0( gsub("_"," ", title.code),"\n(",species,")\nPSI.threshold = ",PSI.threshold,"\ncanonical SJs min = ",min.canonical.control.SJs )

pdf(graph1)
p <- ggplot(crypt.res.classified,
            aes(x=as.numeric(log2FoldChange),
                y=log10(meanBase), 
                colour=family,
                alpha=family,
                label=fix.gene.names,
                shape=factor(!is.na(in.Ling)) ))

p <- p + geom_point(size = 2) + 
scale_alpha_manual(guide='none', values = list(FEW.READS = 0.4, SJ.UNSUPPORTED = 0.4, SJ.SUPPORTED= 0.9, SMALL.FOLDCHANGE = 0.4)) + 
geom_vline(xintercept = c(-0.6,0.6),linetype = 2, colour = "gray") +
geom_hline(yintercept = 0.5, linetype = 2, colour = "gray") + 
ggtitle(label=graph_title) + 
xlim(-3,3) +
scale_shape_discrete(name = expression(paste("Seen in ", italic("Ling et al, 2015"))),
                    labels = c("No","Yes") ) +
scale_colour_manual(name="Classification",
                    values = c("skyblue","firebrick3","goldenrod","skyblue"),
                    breaks=c("SJ.SUPPORTED", "SJ.UNSUPPORTED", "SMALL.FOLDCHANGE","FEW.READS"),
                    labels=c("Supported by splice junctions", "Not supported by splice junctions", "Insufficient fold change","Insufficient read depth")) +
xlab("log2(Fold change)") +
ylab("log10(Mean read count across all samples)")
p + theme_bw() + 
theme(panel.background = element_rect(fill = "white"),
      plot.title = element_text(face = "bold",size = rel(1.2), hjust = 0.5),
      axis.line = element_line(colour = "black")
     )
dev.off()

# pdf(graph1.5)
# ggplot(crypt.res.classified,aes(x=class,fill=family)) + geom_bar() + 
# theme(legend.position="none") + 
# theme(axis.text.x=element_text(angle = 45, hjust = 1)) + 
# geom_text(size = 5, aes(y = ((..count..)/sum(..count..)), label = scales::percent((..count..)/sum(..count..))), vjust = -1)
# dev.off()

pdf(graph2)
p <- ggplot(crypt.res.classified[crypt.res.classified$family=="SJ.SUPPORTED",], aes(y=upstream_delta_psi,x=downstream_delta_psi,colour = PSI.class))
p + geom_point() + ylim(0,1) + xlim(0,1) + xlab("Downstream Delta PSI") + ylab("Upstream Delta PSI") + ggtitle(graph_title)
dev.off()




outfile_total <- paste0(outFolder, "/", code, "_", condition.names, "_splicing_analysis.tab")
outfile_report <- paste0(outFolder, "/", code, "_", condition.names, "_cryptic_exon_report.csv")
# create an easily readable output table containing the gene name. the cryptic exon coordinates, the canonical coordinates, the strand and the level of inclusion.

d <- crypt.res.classified
d <- d[order(d$pvalue),]
cryptic.report <- data.frame(gene.name = d$fix.gene.names,
							cryptic.id = paste(d$fix.gene.names,str_split_fixed(d$exonID,"i",2)[,1], sep = "_" ),
							strand = d$fix.strand,
							tags.chr = d$chr,
							tag.start = d$exon.start,
							tag.end = d$exon.end,
							meanBase = d$meanBase,
							canonical.control.mean.SJ = d$canonical.control.mean.SJ,
							log2FoldChange = d$log2FoldChange,
							pvalue = d$pvalue,
							FDR = d$FDR,
							intron.chr = d$canonical.chr,
							intron.start = d$canonical.start,
							intron.end = d$canonical.end,
							upstream.delta.percent.spliced.in = d$upstream_delta_psi,
							downstream.delta.percent.spliced.in = d$downstream_delta_psi,
							class = d$class,
							splicing.type = d$PSI.class,
							seen.in.Ling = d$in.Ling
							)

write.table(cryptic.report, outfile_report, quote=F,sep=",",row.names=F,col.names=T)
write.table(crypt.res.classified, outfile_total, quote=F, sep="\t",row.names=F,col.names=T)

Rdata <- paste0(outFolder, "/", code, "_", condition.names, "_splicing_analysis.Rdata")
save.image(Rdata)


quit()
end


##################
# Motif Searching
###################
# Very similar to Repeat Masker but give a little more leeway. Window the exon region by 100bp

crypt.res.classified <- d

MOTIF.outFolder <- paste(dirname(outFolder),"Motif_Finding", sep = "/")
if(species == "mouse"){	
	genome.fa <- "/cluster/scratch3/vyp-scratch2/reference_datasets/RNASeq/Mouse/mm10.fa"
}
if(species == "human"){
	genome.fa <- "/cluster/scratch3/vyp-scratch2/reference_datasets/human_reference_sequence/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fa "
}

if (! file.exists(MOTIF.outFolder)) dir.create(MOTIF.outFolder)
cmd.list <- list()
MOTIF.bed <- crypt.res.classified[,c(10,11,12,45,52,46)]
MOTIF.bed[,4] <- paste0(crypt.res.classified[,45], "_", crypt.res.classified[,3])
MOTIF.bed[,2] <- MOTIF.bed[,2] - 100
MOTIF.bed[,3] <- MOTIF.bed[,3] + 100
# make 4 separate files - Intron retention up and down, Cryptic exons up and down.
class.list <- unique(MOTIF.bed$class)
for(i in 1:length(class.list)){
	MOTIF.bed.name <- paste0(condition.names,"_", class.list[i],".MOTIF.bed")
	MOTIF.fasta.name <- paste0(MOTIF.outFolder,"/",condition.names,"_",class.list[i],".MOTIF.fasta")
	MOTIF.bed.out <- paste0(MOTIF.outFolder,"/",MOTIF.bed.name)
	class.MOTIF.bed <- subset(MOTIF.bed, class == class.list[i])
	write.table(class.MOTIF.bed, MOTIF.bed.out, quote=F,col.names=F,row.names=F,sep="\t")
	MOTIF.cmd <- paste0("bedtools getfasta -s -name -fi ",genome.fa," -bed ",MOTIF.bed.out," -fo ",MOTIF.fasta.name)
	cmd.list[i] <- MOTIF.cmd
	system(MOTIF.cmd)
	#assign(MOTIF.bed.name,class.MOTIF.bed)
}

cmd.list.out <- paste0(MOTIF.outFolder,"/",code,"_",condition.names,".MOTIF.list.sh")
write.table(cmd.list,cmd.list.out,quote=F, row.names=F,col.names=F,sep="\n")















if(exists(crypt.counts.classified)){
	# harmonise everything so there should always be a crypt.res.classified which contains absolutely everything
	crypt.res.classified <- cryptic.classifier(crypt.res)
	crypt.res.classified <- subset(crypt.res.classified, !is.na(class))
	crypt.res.classified$family <- str_split_fixed(crypt.res.classified$class, pattern = "[.]UP|[.]DOWN",3)[,1]
	crypt.res.classified$in.Ling <- ling.list[match(crypt.res.classified$fix.gene.names,ling.list)]
}

#Writing outputs for next steps
# IGV:  need list of the canonical introns within which the cryptic exon dwells and a list of the cryptic sites too. So two separate bed files. The IGV batch file will look up the intron coordinates (+ 50bp either side) but will also load the cryptic site bed file as a comparison.

###################
# iCLIP analysis: requires a list of cryptic sites as a bed file. Separate bed files by classification? Name is $4, Score is $5, Strand is $6. Score can be classification Put exon ID as $7.
####################

# Keep all the results and do the closest analysis with the original output coordinates.

# I should have separate iCLIP analyses for Cryptic Exons and Retained Introns.
iCLIP.outFolder <- paste(dirname(outFolder),"iCLIP", sep = "/")
if (! file.exists(iCLIP.outFolder)) dir.create(iCLIP.outFolder)
# include EnsemblID!
iCLIP.bed <- crypt.res.classified[,c(10,11,12,45,49,46)]
iCLIP.bed$canonical.length <- crypt.res.classified$canonical.end - crypt.res.classified$canonical.start
iCLIP.bed <- iCLIP.bed[order(iCLIP.bed$chromosome, iCLIP.bed$exon.start),]
iCLIP.bed$fix.strand <- gsub("-1","-",iCLIP.bed$fix.strand,fixed=T)
iCLIP.bed$fix.strand <- gsub("1","+",iCLIP.bed$fix.strand,fixed=T)
# # create separate lists for cryptic exons and retained introns
# cryptic.exons_iCLIP <- subset(iCLIP.bed, grepl("CRYPTIC",iCLIP.bed$class))

# # For retained introns, the iCLIP cluster should be sought from a point at the centre of the intron. 
# retained.introns_iCLIP <- subset(iCLIP.bed, grepl("INTRON",iCLIP.bed$class))
# retained.introns_iCLIP$canonical.start <- crypt.res.classified$canonical.start[match(row.names(retained.introns_iCLIP),row.names(crypt.res.classified))]
# retained.introns_iCLIP$exon.start <- ceiling(retained.introns_iCLIP$canonical.start + ( retained.introns_iCLIP$canonical.length / 2 ))
# retained.introns_iCLIP$exon.end <- retained.introns_iCLIP$exon.start + 1 
# # remove canonical.start column
# retained.introns_iCLIP$canonical.start <- NULL

# # put the cryptic exons and retained introns back in the same file and sort
# iCLIP.bed <- rbind(cryptic.exons_iCLIP,retained.introns_iCLIP)
iCLIP.bed <- iCLIP.bed[order(iCLIP.bed$chromosome, iCLIP.bed$exon.start),]
outfile_iCLIP <- paste0(iCLIP.outFolder, "/", code, "_", condition.names, "_iCLIP.bed")

# output has to be sorted!
iCLIP.bed$exon.start <- round(iCLIP.bed$exon.start)
iCLIP.bed$exon.end <- round(iCLIP.bed$exon.end)
write.table(iCLIP.bed, outfile_iCLIP, quote=F,sep="\t",row.names=F,col.names=F)

# you can run bedtools via fread.

# BEDTOOLS CLOSEST ANALYSIS
# OPTION 1: F210I mouse - compare WT and Mutant iCLIP clusters
if( species == "mouse" & grepl("F210I",code)){

	iCLIP.out.file <- paste0(iCLIP.outFolder,"/F210I_embryo_all_candidates_both_CLIP.tab")
	CLIP.df <- data.frame(file.name = c("F210I_WT_lowFDR_clusters","F210I_HOM_lowFDR_clusters"),
		file.bed=c(
		"/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting/F210I_mouse/iCLIP/clusters/WT_lowFDR_clusters_stranded.bed.gz",
		"/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting/F210I_mouse/iCLIP/clusters/F210I_lowFDR_clusters_stranded.bed.gz"),
		out.file=c("WT_iCLIP_closest","F210I_iCLIP_closest"),
		stringsAsFactors=F)

	for(i in 1:length(row.names(CLIP.df))){
		cmd <- paste0("bedtools closest -a ",outfile_iCLIP," -b ", CLIP.df[i,2] ," -s -D a")
		closest <- fread(cmd)
		closest$iCLIP <- CLIP.df[i,1]
		assign(CLIP.df[i,3],closest)
		}

	both <- rbind(WT_iCLIP_closest,F210I_iCLIP_closest)
	names(both) <- c("exon.chr","exon.start", "exon.end", "gene.id", "exon.class","exon.strand", "intron.length", "cluster.chr", "cluster.start", "cluster.end", "cluster.score", "cluster.blank", "cluster.strand", "cluster.distance","iCLIP.clusters") 
	outFolder <- paste(dirname(outFolder),"iCLIP", sep = "/")
	iCLIP.out.file <- paste0(outFolder,"/F210I_embryo_all_candidates_both_CLIP.tab")
	write.table(both,"F210I_embryo_all_candidates_both_CLIP.tab",sep="\t",quote=F,row.names=F,col.names=T)
	closest <- subset(both, iCLIP.clusters == "F210I_WT_lowFDR_clusters")
}

# OPTION 2: Human TDP knockdown datasets - compare with Human ES and Brain? iCLIP datasets
if( species == "human"){
	iCLIP.out.file <- paste0(iCLIP.outFolder,"/",code,"iCLIP_analysis")
	CLIP.df <- data.frame(
		file.name = paste0(code,"_Human_ES_lowFDR_clusters"),
		file.bed = paste0(dirname(dirname(iCLIP.outFolder)),"/iCLIP/Human_ES_TDP_iCLIP_clusters_hg38_stranded.bed"),
		out.file = paste0(code,"_iCLIP_closest"),
		stringsAsFactors = F)

	for(i in 1:length(row.names(CLIP.df))){
		cmd <- paste0("bedtools closest -a ",outfile_iCLIP," -b ", CLIP.df[i,2] ," -s -D a")
		closest <- fread(cmd)
		closest$iCLIP <- CLIP.df[i,1]
		anno <- as.data.frame(fread(annotation))
		}
		names(closest) <- c("exon.chr","exon.start", "exon.end", "gene.id", "exon.class","exon.strand", "intron.length", "cluster.chr", "cluster.start", "cluster.end", "cluster.score", "cluster.blank", "cluster.strand", "cluster.distance","iCLIP.clusters") 
		closest$gene.start <- anno$start_position[match(closest$gene.id, anno$external_gene_name)]
	 	closest$gene.end <- anno$end_position[match(closest$gene.id, anno$external_gene_name)]
	 	within.genes <- subset(closest,(cluster.end <= gene.end) & (cluster.start >= gene.start))
		within.genes$is.cluster.within.gene <- "PASS"
		outside.genes <- subset(closest,(cluster.end > gene.end) | (cluster.start < gene.start))
		outside.genes$is.cluster.within.gene <- "FAIL"
		closest <- rbind(within.genes,outside.genes)		
	

	iCLIP.out.file <- paste0(iCLIP.outFolder,"/",code,"_",condition.names,"_iCLIP_closest.tab")
	write.table(closest,iCLIP.out.file, sep="\t",quote=F,row.names=F,col.names=T)


}

if( species == "mouse" & !grepl("F210I",code)){
	iCLIP.out.file <- paste0(iCLIP.outFolder,"/",code,"iCLIP_analysis")
	CLIP.df <- data.frame(file.name = c("F210I_WT_lowFDR_clusters"),
		file.bed=
		"/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting/F210I_mouse/iCLIP/clusters/WT_lowFDR_clusters_stranded.bed.gz",
		out.file=c("WT_iCLIP_closest"),
		stringsAsFactors=F)

	cmd <- paste0("bedtools closest -a ",outfile_iCLIP," -b ", CLIP.df[1,2] ," -s -D a")
	closest <- fread(cmd)
	closest$iCLIP <- CLIP.df[1,1]
	anno <- as.data.frame(fread(annotation))
	

	names(closest) <- c("exon.chr","exon.start", "exon.end", "gene.id", "exon.class","exon.strand", "intron.length", "cluster.chr", "cluster.start", "cluster.end", "cluster.score", "cluster.blank", "cluster.strand", "cluster.distance","iCLIP.clusters") 
	closest$gene.start <- anno$start_position[match(closest$gene.id, anno$external_gene_name)]
	closest$gene.end <- anno$end_position[match(closest$gene.id, anno$external_gene_name)]
	within.genes <- subset(closest,(cluster.end <= gene.end) & (cluster.start >= gene.start))
	within.genes$is.cluster.within.gene <- "PASS"
	outside.genes <- subset(closest,(cluster.end > gene.end) | (cluster.start < gene.start))
	outside.genes$is.cluster.within.gene <- "FAIL"
	closest <- rbind(within.genes,outside.genes)		
	
	iCLIP.out.file <- paste0(iCLIP.outFolder,"/",code,"_",condition.names,"_iCLIP_closest.tab")
	write.table(closest,iCLIP.out.file, sep="\t",quote=F,row.names=F,col.names=T)


}
# generalise for closest
# Only include the exons where the iCLIP cluster is actually within the coordinates of the gene. 
#BUT: I need to express the final values as proportions of the initial total.
# make a table with the original numbers of exons in each class.
class.numbers <- as.data.frame(table(closest$exon.class))
min.cluster <- 1
closest <- subset(closest, is.cluster.within.gene == 'PASS' & abs(cluster.score >= min.cluster) )

plot.list <- c()
n = 1
for(class in unique(closest$exon.class)){
  df <- subset(closest,exon.class == class)
  df$cluster.distance.intron <- df$cluster.distance / df$intron.length
  classer <- function(subset.df,classification){
    if(dim(subset.df)[1] > 0){
      subset.df$class <- classification
      return(subset.df$class)
    }
  }
  
  zero <- subset(df,df$cluster.distance == 0)
  zero$distance <- classer(zero,"zero")
  upto_one <- subset(df,df$cluster.distance.intron <= 1 & df$cluster.distance.intron > 0)
  upto_one$distance <- classer(upto_one,"upto_one")
  downto_minus_one <- subset(df,df$cluster.distance.intron >= -1 & df$cluster.distance.intron < 0)
  downto_minus_one$distance <- classer(downto_minus_one,"downto_minus_one")
  from_one <- subset(df,df$cluster.distance.intron > 1)
  from_one$distance <- classer(from_one,"from_one")
  from_minus_one <- subset(df,df$cluster.distance.intron < -1)
  from_minus_one$distance <- classer(from_minus_one,"from_minus_one")
  df <- rbind(from_minus_one,downto_minus_one,zero,upto_one,from_one,fill=T)
  
  df$distance <- factor(df$distance, levels = c('from_minus_one','downto_minus_one','zero','upto_one','from_one'))
  
  # summarise this into count tables for graphing
  distance.table <- as.data.frame(table(df$distance))
  distance.table$exon.class <- class
  distance.table$class.number <- as.numeric(class.numbers$Freq[match(distance.table$exon.class, class.numbers$Var1)])
  distance.table$Freq.proportion <- distance.table$Freq / distance.table$class.number
  distance.table$family <- str_split_fixed(distance.table$exon.class, pattern = "[.]UP|[.]DOWN",3)[,1]
  distance.table$is.zero <- ifelse(distance.table$Var1 == "zero", TRUE, FALSE)
  plot.list[[n]] <- distance.table
  
  n <- n + 1
}


distance.table <- rbindlist(plot.list)
pdf(paste0(iCLIP.outFolder,"/",code,"_",condition.names,"_iCLIP_closest_by_class",min.cluster,"cluster_min.pdf"), paper="a4r")
p <- ggplot(distance.table, 
		aes(x=Var1,y=Freq.proportion,group = exon.class, fill = family, label = Freq,colour = is.zero)) + 
		geom_bar(stat="identity") + 
		theme(legend.position="none", strip.text = element_text(size=6)) +
		xlab("Cluster distance from site normalised by intron length") +
		geom_text(size = 4, aes(y = Freq.proportion),colour='black', vjust = -0.5) +
		scale_colour_manual(values = c("white","black")) +
		scale_x_discrete(breaks=c('from_minus_one','downto_minus_one','zero','upto_one','from_one'),labels=c("<-1","-1-0","0","0-1",">1")) +
		facet_wrap(facets = ~exon.class,nrow = 2) +
		ggtitle(code)
print(p)
dev.off()

# for presenting the distance table
distance.table <- as.data.frame(distance.table)
distance.table <- distance.table[,c(1,2,3,5)]
distance.table$percent <- signif(distance.table$Freq.proportion * 100,digits = 3)
distance.table <- dcast(distance.table,formula = Var1 ~ exon.class, value.var = "percent" )
distance.table[,1] <- c("Upstream more than 1 intron length","Upstream within 1 intron length", "Overlapping","Downstream within 1 intron length","Downstream more than 1 intron length")
distance.table <- distance.table[c(3,1,2,4,5),]

distance.table.out <- 

# The IGV stuff
	
	# harmonise everything so there should always be a crypt.res.classified which contains absolutely everything
	crypt.res.classified <- cryptic.classifier(crypt.res)
	crypt.res.classified <- subset(crypt.res.classified, !is.na(class))
	crypt.res.classified$family <- str_split_fixed(crypt.res.classified$class, pattern = "[.]UP|[.]DOWN",3)[,1]
	crypt.res.classified$in.Ling <- ling.list[match(crypt.res.classified$fix.gene.names,ling.list)]
# I want to take the crypt.res.classified and create a bed file for processing by bedtools
# requires the start and end to be the canonical intron coordinates with 50bp slop
IGV.outFolder <- paste(dirname(outFolder),"IGV", sep = "/")
if (! file.exists(IGV.outFolder)) dir.create(IGV.outFolder)

IGV.bed <- data.frame(chr = crypt.res.classified$canonical.chr,
	start = crypt.res.classified$canonical.start - 50 , 
	end = crypt.res.classified$canonical.end + 50, 
	name = paste0(row.names(crypt.res.classified),"_",crypt.res.classified$fix.gene.names,"_",crypt.res.classified$exonID),
	class = crypt.res.classified$class, row.names = row.names(crypt.res.classified))
# remove NOISE class. Don't need to look at them.
IGV.bed <- IGV.bed[IGV.bed$class != "NOISE",]
# ain't nobody got time to look at all the "POSSIBLE" events. remove them.
IGV.bed <- IGV.bed[!grepl("POSSIBLE",IGV.bed$class),]
IGV.bed <- IGV.bed[order(as.numeric(row.names(IGV.bed))),]
# write the bed file to the splice_junction_analysis folder
IGV.outfile.bed <- paste0(IGV.outFolder, "/", code, "_", condition.names, "_IGV.bed")
write.table(IGV.bed, IGV.outfile.bed, quote=F,sep="\t",row.names=F,col.names=F)
# create the bedtools command
snapshot.path <- paste0("/Users/Jack/Documents/Cryptic_Exons/IGV_snapshots/",code,"_",condition.names)
cmd <- paste0("bedtools igv -i ",IGV.outfile.bed," -name -path ",snapshot.path)
message(snapshot.path)
IGV.batchfile <- fread(cmd)
IGV.outfile.batch <- paste0(IGV.outFolder, "/", code, "_", condition.names, "_IGV_batchfile.txt")
write.table(IGV.batchfile,IGV.outfile.batch,row.names=F,quote=F)
# BedTools for some reason puts the coordinates at the start of the name. Here's a quick bit of awk to remove that. 
awk.string <- 'awk -F\' \' \'NR ==1 {print $0;next} NR % 2 == 0 {print $0} NR % 2 == 1 {split($2,a,"_"); print $1,a[4]"_"a[5]"_"a[6]}\''
IGV.batchfile <- fread(paste(awk.string, IGV.outfile.batch))
write.table(IGV.batchfile,IGV.outfile.batch,row.names=F,quote=F)
# create csv file I can use to enter observations etc in EXCEL
IGV.out.csv <- paste0(IGV.outFolder, "/", code, "_", condition.names, "_IGV.csv")
write.csv(IGV.bed,IGV.out.csv)



Rdata <- paste0(outFolder, "/", code, "_", condition.names, "_splicing_analysis.Rdata")
save.image(Rdata)
#########################
# The RepeatMasker Stuff
#########################
# again create a bed file. Output it to BedTools getfasta. Requires the input FASTA to be known.
#bedtools getfasta [OPTIONS] -s -name -fi <fasta> -bed <bed/gff/vcf> -fo <fasta>

RM.outFolder <- paste(dirname(outFolder),"RepeatMasker", sep = "/")
if (! file.exists(RM.outFolder)) dir.create(RM.outFolder)
cmd.list <- list()
RM.bed <- crypt.res.classified[,c(10,11,12,45,49,46)]
RM.bed[,4] <- paste0(crypt.res.classified[,45], "_", crypt.res.classified[,3])
# make 4 separate files - Intron retention up and down, Cryptic exons up and down.
class.list <- unique(RM.bed$class)
for(i in 1:length(class.list)){
	RM.bed.name <- paste0(condition.names,"_", class.list[i],".RM.bed")
	RM.fasta.name <- paste0(RM.outFolder,"/",condition.names,"_",class.list[i],".RM.fasta")
	RM.bed.out <- paste0(RM.outFolder,"/",RM.bed.name)
	class.RM.bed <- subset(RM.bed, class == class.list[i])
	write.table(class.RM.bed, RM.bed.out, quote=F,col.names=F,row.names=F,sep="\t")
# this command works when just typed in but not when going via fread. Weird.
	RM.cmd <- paste0("bedtools getfasta -s -name -fi ",genome.fa," -bed ",RM.bed.out," -fo ",RM.fasta.name)
	cmd.list[i] <- RM.cmd
	#RM.fasta <- fread(RM.cmd)
	assign(RM.bed.name,class.RM.bed)
}
cmd.list.out <- RM.fasta.name <- paste0(RM.outFolder,"/",code,"_",condition.names,".RM.list.sh")
write.table(cmd.list,cmd.list.out,quote=F, row.names=F,col.names=F,sep="\n")





#################################
# Intersecting multiple datasets
#################################
# I should focus on intersecting the canonical introns first and then entire genes next?
# read in the cooords tables
outFolder <- "/cluster/project8/vyp/Humphrey_RNASeq_brain/jack_git/Humphrey_RNASeq_brain/splice_junction_detection/extended_hunting/"

d1 <- "TDP_ENCODE_human/dataset_1/splice_junction_analysis/dataset_1_control_TDP_splicing_coords.tab"
d2 <- "TDP_ENCODE_human/dataset_2/splice_junction_analysis/dataset_2_control_TDP_splicing_coords.tab"
chiang <- "paper_TDP_mouse/Chiang_processed/splice_junction_analysis/Chiang_processed_CTL_TDP_splicing_coords.tab"
cleve <- "paper_TDP_mouse/Cleveland_TDP43/splice_junction_analysis/Cleveland_TDP43_CTL_TDP_splicing_coords.tab"
deltaTDP43_embryo_HOM <- "F210I_mouse/Fratta_F210I_embryo/splice_junction_analysis/Fratta_F210I_embryo_CTL_HOM_splicing_coords.tab"
deltaTDP43_embryo_HET <- "F210I_mouse/Fratta_F210I_embryo/splice_junction_analysis/Fratta_F210I_embryo_CTL_HET_splicing_coords.tab"

encode.comparison.df <- data.frame(file.names = c("Dataset_1","Dataset_2"),
		input.files = c(d1,d2),
		class=c("dataset_1_class","dataset_2_class"),
		output.folder = paste0(outFolder,"/TDP_ENCODE_human/comparing_datasets/intron_intersect/"),
		species = "human",
		stringsAsFactors=F)

mouse.comparison.df <- data.frame(file.names = c("Chiang","Cleveland"),
		input.files = c(chiang,cleve),
		class = c("Chiang_class","Cleveland_class"),
		output.folder = paste0(outFolder,"/paper_TDP_mouse/comparing_datasets/intron_intersect/"),
		species = "mouse",
		stringsAsFactors=F)

F210I.Cleve.comparison.df <- data.frame(file.names = c("Cleveland","deltaTDP43_embryo_HOM"),
		input.files = c(cleve, deltaTDP43_embryo_HOM),
		class = c("Cleveland_class", "deltaTDP_embryo_HOM_class"),
		output.folder = paste0(outFolder, "/F210I_mouse/comparing_datasets/intron_intersect/"),
		species = "mouse",
		stringsAsFactors = F)

F210I.Chiang.comparison.df <- data.frame(file.names = c("Chiang","deltaTDP43_embryo_HOM"),
		input.files = c(chiang, deltaTDP43_embryo_HOM),
		class = c("Chiang_class", "deltaTDP_embryo_HOM_class"),
		output.folder = paste0(outFolder, "/F210I_mouse/comparing_datasets/intron_intersect/"),
		species = "mouse",
		stringsAsFactors = F)

F210I.F210I.comparison.df <- data.frame(file.names = c("deltaTDP43_embryo_HET","deltaTDP43_embryo_HOM"),
		input.files = c(deltaTDP43_embryo_HET, deltaTDP43_embryo_HOM),
		class = c("deltaTDP43_embryo_HET_class", "deltaTDP43_embryo_HOM_class"),
		output.folder = paste0(outFolder, "/F210I_mouse/comparing_datasets/intron_intersect/"),
		species = "mouse",
		stringsAsFactors = F)

# for testing!
comparison <- F210I.Chiang.comparison.df
comparison <- F210I.Cleve.comparison.df




# Compare each pair of datasets using BedTools intersect. Output graphs by Class grouping
for(comparison in list(encode.comparison.df, mouse.comparison.df)){
	if(comparison$species[1] == "mouse"){	
		genome.fa <- "/cluster/scratch3/vyp-scratch2/reference_datasets/RNASeq/Mouse/mm10.fa"
	}
	if(comparison$species[1] == "human"){
		genome.fa <- "/cluster/scratch3/vyp-scratch2/reference_datasets/human_reference_sequence/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fa "
	}
	bed.names <- c("chr","start","end","gene.name","class","strand")
	comparison$output.bed <- paste0(comparison$output.folder,comparison$file.names,"_introns_classified.bed")
	# stupid hack due to adding the species column earlier.
	comparison <- comparison[,c(1,2,3,4,6,5)]
	# make directory
	if (! file.exists(comparison[1,4])) dir.create(comparison[1,4],recursive=T)
	

	for(i in 1:2){
		dataset <- read.table(paste0(outFolder, comparison[i,2]),header=T)
		# subset out just the canonical intron coordinates plus class and strand
		dataset <- dataset[,c(7:9,1,32,10)]
 		# write out
		write.table(dataset, comparison[i,5],row.names=F,col.names=F,quote=F,sep="\t")
	}
	# create bedtools command to intersect the two intron bed files.
	# -loj keeps all the entries in the second file that do not overlap with the first. 
	# Need to do this twice and then bind together and remove duplicates
	one.intersect.both.cmd <- paste0("bedtools intersect -s -a ", comparison[1,5]," -b ", comparison[2,5], " -loj")
	two.intersect.both.cmd <- paste0("bedtools intersect -s -a ", comparison[2,5]," -b ", comparison[1,5], " -loj")
	
	one.compare.both <- as.data.frame(fread(one.intersect.both.cmd))
	names(one.compare.both)[1:6] <- paste0(comparison[1,1], ".", bed.names)
	names(one.compare.both)[7:12] <- paste0(comparison[2,1], ".", bed.names)
	# two.compare needs to be flipped round
	two.compare.both <- as.data.frame(fread(two.intersect.both.cmd))
	two.compare.both <- two.compare.both[,c(7:12,1:6)]
	names(two.compare.both)[1:6] <- paste0(comparison[1,1], ".", bed.names)
	names(two.compare.both)[7:12] <- paste0(comparison[2,1], ".", bed.names)
	# remove the overlapping exons so as to not to have duplicate entries
	two.compare.both <- subset(two.compare.both,two.compare.both[,5] == "-1")

	# Rbind cares about column names!
	all.compare.both <- rbind(one.compare.both,two.compare.both)
	all.compare.both[,5] <- gsub(pattern = "-1", replacement = "ABSENT", x = all.compare.both[,5],fixed=T)	
	all.compare.both[,11] <- gsub(pattern = "-1", replacement = "ABSENT", x = all.compare.both[,11],fixed=T)	
	class <- unique(c(sort(all.compare.both[,5]), sort(all.compare.both[,11])) )
	#generate list of all pairs possible 
	heatmap.full <- expand.grid(class,class)
	# create table of counts of all the possible pairings
	heatmap.nonzero <- as.data.frame(table(paste(all.compare.both[,5], all.compare.both[,11])))
	heatmap.full$Freq <- heatmap.nonzero$Freq[match(paste(heatmap.full$Var1, heatmap.full$Var2),heatmap.nonzero$Var1)]
	#heatmap.full[is.na(heatmap.full)] <- "0"

	# output table of shared exons
	shared <- subset(all.compare.both, all.compare.both[,5] == all.compare.both[,11])
	shared.bed <- shared[,1:6]
	shared.out.bed <- paste0(comparison[1,4],"shared_exons.bed")
	write.table(shared.bed, shared.out.bed, col.names=T,row.names=F,quote=F,sep="\t")
	names(shared.bed) <- str_split_fixed(names(shared.bed),'[.]',2)[,2]

	class.list <- unique(shared.bed$class)
	shared.outFolder <- comparison[1,4]
	cmd.list <- c()
	for(i in 1:length(class.list)){
		shared.bed.name <- paste0( class.list[i],".shared.bed")
		shared.fasta.name <- paste0(shared.outFolder,"/",class.list[i],".shared.fasta")
		shared.bed.out <- paste0(shared.outFolder,"/",shared.bed.name)
		class.shared.bed <- subset(shared.bed, class == class.list[i])
		write.table(class.shared.bed, shared.bed.out, quote=F,col.names=F,row.names=F,sep="\t")
# this command works when just typed in but not when going via fread. Weird.
		shared.cmd <- paste0("bedtools getfasta -s -name -fi ",genome.fa," -bed ",shared.bed.out," -fo ",shared.fasta.name)
		cmd.list[i] <- shared.cmd
	#shared.fasta <- fread(shared.cmd)
		assign(shared.bed.name,class.shared.bed)
	}
	cmd.list.out <- paste0(shared.outFolder,"/",code,"_",condition.names,".shared.list.sh")
	write.table(cmd.list,cmd.list.out,quote=F, row.names=F,col.names=F,sep="\n")

	# output shared exon bed and FASTA making command
	


	pdf(paste0(comparison[1,4],comparison[1,1],"_",comparison[2,1],"_class_pair_comparisons.pdf"),paper="a4r")

	p <- ggplot(heatmap.full,aes(x = Var1,y =Var2,fill=factor(Var1 == Var2),label = Freq)) + 
		geom_tile(size=0.5) + 
		geom_text(size=3) + 
		xlab(paste0(comparison[1,1], "\nClassification")) + 
		ylab(paste0(comparison[2,1], "\nClassification")) + 
		theme(legend.position="none") + 
		theme(axis.title.y = element_text(angle = 0, hjust = 1,size = 5)) +
		theme(axis.text.x= element_text(angle = 45, hjust = 1))
	print(p)
	dev.off()
}
